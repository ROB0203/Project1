# Project1
Created 2 fully connected feedforward nueral network for digit classification on MNIST data 
Both networks have 10 hidden layers each having 10 nuerons
In the first nueral network only sigmoid activation function has been used
In the 2nd network ReLU is used in all places except in the output layer which uses sigmoid
Network has been trained using ADAM optimizer, with 64 batch size, learning rate 0.0001 and error function is cross entropy
